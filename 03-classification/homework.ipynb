{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we will use the Car price dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv).\n",
    "\n",
    "Or you can do it with `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv\n",
    "```\n",
    "\n",
    "We'll keep working with the `MSRP` variable, and we'll transform it to a classification task. \n",
    "\n",
    "### Features\n",
    "\n",
    "For the rest of the homework, you'll need to use only these columns:\n",
    "\n",
    "* `Make`,\n",
    "* `Model`,\n",
    "* `Year`,\n",
    "* `Engine HP`,\n",
    "* `Engine Cylinders`,\n",
    "* `Transmission Type`,\n",
    "* `Vehicle Style`,\n",
    "* `highway MPG`,\n",
    "* `city mpg`,\n",
    "* `MSRP`\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Select only the features from above and transform their names using the next line:\n",
    "  ```  data.columns = data.columns.str.replace(' ', '_').str.lower()  ```\n",
    "* Fill in the missing values of the selected features with 0.\n",
    "* Rename `MSRP` variable to `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `transmission_type`?\n",
    "\n",
    "- `AUTOMATIC`\n",
    "- `MANUAL`\n",
    "- `AUTOMATED_MANUAL`\n",
    "- `DIRECT_DRIVE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the median (50% percentile) for variable `'population'`?\n",
    "\n",
    "- 995\n",
    "- 1095\n",
    "- 1195\n",
    "- 1295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.population.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and split the dataset\n",
    "\n",
    "* Shuffle the dataset (the filtered one you created above), use seed `42`.\n",
    "* Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "* Apply the log transformation to the `median_house_value` variable using the `np.log1p()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1, as indicated in the lesson\n",
    "\n",
    "n = len(df)\n",
    "\n",
    "n_val = int(n * 0.2)\n",
    "n_test = int(n * 0.2)\n",
    "n_train = n - n_val - n_test\n",
    "\n",
    "idx = np.arange(n)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "df_train = df.iloc[idx[:n_train]]\n",
    "df_validate = df.iloc[idx[n_train:n_train + n_val]]\n",
    "df_test = df.iloc[idx[n_train + n_val:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2, my preference, with random state instead of seed\n",
    "\n",
    "# df_validate, df_test, df_train = np.split(df.sample(frac = 1, random_state = 42), [int(0.2 * len(df)), int(0.4 * len(df))])\n",
    "\n",
    "# df_train = df_train.reset_index(drop = True)\n",
    "# df_validate = df_validate.reset_index(drop = True)\n",
    "# df_test = df_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log1p(df_train.median_house_value.values)\n",
    "y_validate = np.log1p(df_validate.median_house_value.values)\n",
    "y_test = np.log1p(df_test.median_house_value.values)\n",
    "\n",
    "del df_train[\"median_house_value\"]\n",
    "del df_validate[\"median_house_value\"]\n",
    "del df_test[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "* We need to deal with missing values for the column from Q1.\n",
    "* We have two options: fill it with 0 or with the mean of this variable.\n",
    "* Try both options. For each, train a linear regression model without regularization using the code from the lessons.\n",
    "* For computing the mean, use the training only!\n",
    "* Use the validation dataset to evaluate the models and compare the RMSE of each option.\n",
    "* Round the RMSE scores to 2 decimal digits using `round(score, 2)`\n",
    "* Which option gives better RMSE?\n",
    "\n",
    "Options:\n",
    "\n",
    "- With 0\n",
    "- With mean\n",
    "- Both are equally good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(X, y):\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    return w_full[0], w_full[1:]\n",
    "\n",
    "def prepare_X_zero(df): # for option with 0\n",
    "    df_num = df\n",
    "    df_num = df_num.fillna(0)\n",
    "    X = df_num.values\n",
    "    return X\n",
    "\n",
    "def prepare_X_mean(df): # for option with mean\n",
    "    df_num = df\n",
    "    df_num = df_num.fillna(value = df_train.total_bedrooms.mean())\n",
    "    X = df_num.values\n",
    "    return X\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    se = (y - y_pred) ** 2\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option with 0\n",
    "\n",
    "X_train = prepare_X_zero(df_train)\n",
    "w0, w = train_linear_regression(X_train, y_train)\n",
    "\n",
    "X_validate = prepare_X_zero(df_validate)\n",
    "y_pred = w0 + X_validate.dot(w)\n",
    "\n",
    "round(rmse(y_validate, y_pred), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option with mean\n",
    "\n",
    "X_train = prepare_X_mean(df_train)\n",
    "w0, w = train_linear_regression(X_train, y_train)\n",
    "\n",
    "X_validate = prepare_X_mean(df_validate)\n",
    "y_pred = w0 + X_validate.dot(w)\n",
    "\n",
    "round(rmse(y_validate, y_pred), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "* Now let's train a regularized linear regression.\n",
    "* For this question, fill the NAs with 0. \n",
    "* Try different values of `r` from this list: `[0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]`.\n",
    "* Use RMSE to evaluate the model on the validation dataset.\n",
    "* Round the RMSE scores to 2 decimal digits.\n",
    "* Which `r` gives the best RMSE?\n",
    "\n",
    "If there are multiple options, select the smallest `r`.\n",
    "\n",
    "Options:\n",
    "\n",
    "- 0\n",
    "- 0.000001\n",
    "- 0.001\n",
    "- 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression_reg(X, y, r):\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX = XTX + r * np.eye(XTX.shape[0])\n",
    "\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    return w_full[0], w_full[1:]\n",
    "\n",
    "r_list = [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]\n",
    "\n",
    "for r in r_list:\n",
    "    X_train = prepare_X_zero(df_train)\n",
    "    w0, w = train_linear_regression_reg(X_train, y_train, r)\n",
    "\n",
    "    X_val = prepare_X_zero(df_validate)\n",
    "    y_pred = w0 + X_val.dot(w)\n",
    "    print(f\"{r} produces {rmse(y_validate, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "* We used seed 42 for splitting the data. Let's find out how selecting the seed influences our score.\n",
    "* Try different seed values: `[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`.\n",
    "* For each seed, do the train/validation/test split with 60%/20%/20% distribution.\n",
    "* Fill the missing values with 0 and train a model without regularization.\n",
    "* For each seed, evaluate the model on the validation dataset and collect the RMSE scores. \n",
    "* What's the standard deviation of all the scores? To compute the standard deviation, use `np.std`.\n",
    "* Round the result to 3 decimal digits (`round(std, 3)`)\n",
    "\n",
    "What's the value of std?\n",
    "\n",
    "- 0.5\n",
    "- 0.05\n",
    "- 0.005\n",
    "- 0.0005\n",
    "\n",
    "> Note: Standard deviation shows how different the values are.\n",
    "> If it's low, then all values are approximately the same.\n",
    "> If it's high, the values are different. \n",
    "> If standard deviation of scores is low, then our model is *stable*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "seed_rmse = []\n",
    "\n",
    "n = len(df)\n",
    "\n",
    "n_val = int(n * 0.2)\n",
    "n_test = int(n * 0.2)\n",
    "n_train = n - n_val - n_test\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    idx = np.arange(n)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    df_train = df.iloc[idx[:n_train]]\n",
    "    df_validate = df.iloc[idx[n_train:n_train + n_val]]\n",
    "    df_test = df.iloc[idx[n_train + n_val:]]\n",
    "\n",
    "    y_train = np.log1p(df_train.median_house_value.values)\n",
    "    y_validate = np.log1p(df_validate.median_house_value.values)\n",
    "    y_test = np.log1p(df_test.median_house_value.values)\n",
    "\n",
    "    del df_train[\"median_house_value\"]\n",
    "    del df_validate[\"median_house_value\"]\n",
    "    del df_test[\"median_house_value\"]\n",
    "\n",
    "    X_train = prepare_X_zero(df_train)\n",
    "    w0, w = train_linear_regression(X_train, y_train)\n",
    "\n",
    "    X_validate = prepare_X_zero(df_validate)\n",
    "    y_pred = w0 + X_validate.dot(w)\n",
    "\n",
    "    seed_rmse.append(rmse(y_validate, y_pred))\n",
    "\n",
    "print(seed_rmse)\n",
    "print(round(np.std(seed_rmse), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "* Split the dataset like previously, use seed 9.\n",
    "* Combine train and validation datasets.\n",
    "* Fill the missing values with 0 and train a model with `r=0.001`. \n",
    "* What's the RMSE on the test dataset?\n",
    "\n",
    "Options:\n",
    "\n",
    "- 0.13\n",
    "- 0.23\n",
    "- 0.33\n",
    "- 0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "n_test = int(n * 0.2)\n",
    "n_train = n - n_test\n",
    "\n",
    "idx = np.arange(n)\n",
    "np.random.seed(9)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "df_train = df.iloc[idx[:n_train]]\n",
    "df_test = df.iloc[idx[n_train:]]\n",
    "\n",
    "y_train = np.log1p(df_train.median_house_value.values)\n",
    "y_test = np.log1p(df_test.median_house_value.values)\n",
    "\n",
    "del df_train[\"median_house_value\"]\n",
    "del df_test[\"median_house_value\"]\n",
    "\n",
    "X_train = df_train.fillna(0)\n",
    "w0, w = train_linear_regression_reg(X_train, y_train, r = 0.001)\n",
    "\n",
    "X_test = df_test.fillna(0)\n",
    "y_pred = w0 + X_test.dot(w)\n",
    "\n",
    "rmse(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
