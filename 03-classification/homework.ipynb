{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we will use the Car price dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv).\n",
    "\n",
    "Or you can do it with `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv\n",
    "```\n",
    "\n",
    "We'll keep working with the `MSRP` variable, and we\"ll transform it to a classification task. \n",
    "\n",
    "### Features\n",
    "\n",
    "For the rest of the homework, you\"ll need to use only these columns:\n",
    "\n",
    "* `Make`,\n",
    "* `Model`,\n",
    "* `Year`,\n",
    "* `Engine HP`,\n",
    "* `Engine Cylinders`,\n",
    "* `Transmission Type`,\n",
    "* `Vehicle Style`,\n",
    "* `highway MPG`,\n",
    "* `city mpg`,\n",
    "* `MSRP`\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Select only the features from above and transform their names using the next line:\n",
    "  ```  data.columns = data.columns.str.replace(\" ', '_').str.lower()  ```\n",
    "* Fill in the missing values of the selected features with 0.\n",
    "* Rename `MSRP` variable to `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Make       Model  Year             Engine Fuel Type  Engine HP  \\\n",
      "0  BMW  1 Series M  2011  premium unleaded (required)      335.0   \n",
      "1  BMW    1 Series  2011  premium unleaded (required)      300.0   \n",
      "2  BMW    1 Series  2011  premium unleaded (required)      300.0   \n",
      "3  BMW    1 Series  2011  premium unleaded (required)      230.0   \n",
      "4  BMW    1 Series  2011  premium unleaded (required)      230.0   \n",
      "\n",
      "   Engine Cylinders Transmission Type     Driven_Wheels  Number of Doors  \\\n",
      "0               6.0            MANUAL  rear wheel drive              2.0   \n",
      "1               6.0            MANUAL  rear wheel drive              2.0   \n",
      "2               6.0            MANUAL  rear wheel drive              2.0   \n",
      "3               6.0            MANUAL  rear wheel drive              2.0   \n",
      "4               6.0            MANUAL  rear wheel drive              2.0   \n",
      "\n",
      "                         Market Category Vehicle Size Vehicle Style  \\\n",
      "0  Factory Tuner,Luxury,High-Performance      Compact         Coupe   \n",
      "1                     Luxury,Performance      Compact   Convertible   \n",
      "2                Luxury,High-Performance      Compact         Coupe   \n",
      "3                     Luxury,Performance      Compact         Coupe   \n",
      "4                                 Luxury      Compact   Convertible   \n",
      "\n",
      "   highway MPG  city mpg  Popularity   MSRP  \n",
      "0           26        19        3916  46135  \n",
      "1           28        19        3916  40650  \n",
      "2           28        20        3916  36350  \n",
      "3           28        18        3916  29450  \n",
      "4           28        18        3916  34500  \n",
      "(11914, 16)\n",
      "Index(['Make', 'Model', 'Year', 'Engine Fuel Type', 'Engine HP',\n",
      "       'Engine Cylinders', 'Transmission Type', 'Driven_Wheels',\n",
      "       'Number of Doors', 'Market Category', 'Vehicle Size', 'Vehicle Style',\n",
      "       'highway MPG', 'city mpg', 'Popularity', 'MSRP'],\n",
      "      dtype='object')\n",
      "Make                    0\n",
      "Model                   0\n",
      "Year                    0\n",
      "Engine Fuel Type        3\n",
      "Engine HP              69\n",
      "Engine Cylinders       30\n",
      "Transmission Type       0\n",
      "Driven_Wheels           0\n",
      "Number of Doors         6\n",
      "Market Category      3742\n",
      "Vehicle Size            0\n",
      "Vehicle Style           0\n",
      "highway MPG             0\n",
      "city mpg                0\n",
      "Popularity              0\n",
      "MSRP                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"./data/data.csv\")\n",
    "print(df_raw.head())\n",
    "print(df_raw.shape)\n",
    "print(df_raw.columns)\n",
    "print(df_raw.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df.drop([\"Engine Fuel Type\", \"Driven_Wheels\", \"Number of Doors\", \"Market Category\", \"Vehicle Size\", \"Popularity\"], axis = 1, inplace = True)\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower() # modified to accommodate df designation \"df\" instead of \"data\"\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.rename(columns={\"msrp\": \"price\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `transmission_type`?\n",
    "\n",
    "- `AUTOMATIC`\n",
    "- `MANUAL`\n",
    "- `AUTOMATED_MANUAL`\n",
    "- `DIRECT_DRIVE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AUTOMATIC           8266\n",
       "MANUAL              2935\n",
       "AUTOMATED_MANUAL     626\n",
       "DIRECT_DRIVE          68\n",
       "UNKNOWN               19\n",
       "Name: transmission_type, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.transmission_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset. \n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
    "\n",
    "What are the two features that have the biggest correlation in this dataset?\n",
    "\n",
    "- `engine_hp` and `year`\n",
    "- `engine_hp` and `engine_cylinders`\n",
    "- `highway_mpg` and `engine_cylinders`\n",
    "- `highway_mpg` and `city_mpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make                  object\n",
       "model                 object\n",
       "year                   int64\n",
       "engine_hp            float64\n",
       "engine_cylinders     float64\n",
       "transmission_type     object\n",
       "vehicle_style         object\n",
       "highway_mpg            int64\n",
       "city_mpg               int64\n",
       "price                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                1.000000\n",
      "engine_hp           0.338714\n",
      "engine_cylinders    0.040708\n",
      "highway_mpg         0.258240\n",
      "city_mpg            0.198171\n",
      "price               0.227590\n",
      "dtype: float64\n",
      "\n",
      "year                0.338714\n",
      "engine_hp           1.000000\n",
      "engine_cylinders    0.774851\n",
      "highway_mpg         0.415707\n",
      "city_mpg            0.424918\n",
      "price               0.650095\n",
      "dtype: float64\n",
      "\n",
      "year                0.040708\n",
      "engine_hp           0.774851\n",
      "engine_cylinders    1.000000\n",
      "highway_mpg         0.614541\n",
      "city_mpg            0.587306\n",
      "price               0.526274\n",
      "dtype: float64\n",
      "\n",
      "year                0.258240\n",
      "engine_hp           0.415707\n",
      "engine_cylinders    0.614541\n",
      "highway_mpg         1.000000\n",
      "city_mpg            0.886829\n",
      "price               0.160043\n",
      "dtype: float64\n",
      "\n",
      "year                0.198171\n",
      "engine_hp           0.424918\n",
      "engine_cylinders    0.587306\n",
      "highway_mpg         0.886829\n",
      "city_mpg            1.000000\n",
      "price               0.157676\n",
      "dtype: float64\n",
      "\n",
      "year                0.227590\n",
      "engine_hp           0.650095\n",
      "engine_cylinders    0.526274\n",
      "highway_mpg         0.160043\n",
      "city_mpg            0.157676\n",
      "price               1.000000\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerical = [\"year\", \"engine_hp\", \"engine_cylinders\", \"highway_mpg\", \"city_mpg\", \"price\"]\n",
    "\n",
    "for feature in numerical:\n",
    "    print(df[numerical].corrwith(df[feature]).abs())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make `price` binary\n",
    "\n",
    "* Now we need to turn the `price` variable from numeric into a binary format.\n",
    "* Let's create a variable `above_average` which is `1` if the `price` is above its mean value and `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"above_average\"] = df[\"price\"]\n",
    "df[\"above_average\"].where(df[\"above_average\"] < df.above_average.mean(), 1, inplace=True)\n",
    "df[\"above_average\"].where(df[\"above_average\"] <= 1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "* Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "* Make sure that the target value (`above_average`) is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.above_average.values\n",
    "y_val = df_val.above_average.values\n",
    "y_test = df_test.above_average.values\n",
    "\n",
    "del df_train[\"above_average\"]\n",
    "del df_val[\"above_average\"]\n",
    "del df_test[\"above_average\"]\n",
    "\n",
    "# although not explicitly noted, it makes sense to also remove price!\n",
    "del df_train[\"price\"]\n",
    "del df_val[\"price\"]\n",
    "del df_test[\"price\"]\n",
    "\n",
    "numerical = [\"year\", \"engine_hp\", \"engine_cylinders\", \"highway_mpg\", \"city_mpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "* Calculate the mutual information score between `above_average` and other categorical variables in our dataset. \n",
    "  Use the training set only.\n",
    "* Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the lowest mutual information score?\n",
    "  \n",
    "- `make`\n",
    "- `model`\n",
    "- `transmission_type`\n",
    "- `vehicle_style`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make\n",
      "0.23976875439118348\n",
      "model\n",
      "0.46234389209653004\n",
      "transmission_type\n",
      "0.02095754189630187\n",
      "vehicle_style\n",
      "0.08414301956779438\n"
     ]
    }
   ],
   "source": [
    "categorical = [\"make\", \"model\", \"transmission_type\", \"vehicle_style\"]\n",
    "\n",
    "for variable in categorical:\n",
    "    print(variable)\n",
    "    print(mutual_info_score(y_train, df_train[variable]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "* Now let's train a logistic regression.\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    - `model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)`\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "- 0.60\n",
    "- 0.72\n",
    "- 0.84\n",
    "- 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE\n",
    "\n",
    "dv = DictVectorizer(sparse = False)\n",
    "\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient = \"records\")\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient = \"records\")\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "\n",
    "model = LogisticRegression(solver = \"liblinear\", C = 10, max_iter = 1000, random_state = 42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9454469156525388\n"
     ]
    }
   ],
   "source": [
    "# Predict accuracy\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "churn_decision = (y_pred >= 0.5)\n",
    "accuracy = (y_val == churn_decision).mean()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "* Let's find the least useful feature using the *feature elimination* technique.\n",
    "* Train a model with all these features (using the same parameters as in Q4).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. \n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- `year`\n",
    "- `engine_hp`\n",
    "- `transmission_type`\n",
    "- `city_mpg`\n",
    "\n",
    "> **Note**: the difference doesn't have to be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make\n",
      "0.0012589173310952884\n",
      "model\n",
      "-0.026017624842635367\n",
      "year\n",
      "0.0025178346621905767\n",
      "engine_hp\n",
      "-0.020981955518254325\n",
      "engine_cylinders\n",
      "0.0012589173310952884\n",
      "transmission_type\n",
      "-0.0008392782207301552\n",
      "vehicle_style\n",
      "-0.0025178346621904657\n",
      "highway_mpg\n",
      "0.0012589173310952884\n",
      "city_mpg\n",
      "0.00041963911036513313\n"
     ]
    }
   ],
   "source": [
    "df_small_train = df_train.copy()\n",
    "df_small_val = df_val.copy()\n",
    "categorical_small = categorical.copy()\n",
    "numerical_small = numerical.copy()\n",
    "\n",
    "for i in df_train.columns:\n",
    "    print(i)\n",
    "    del df_small_train[i]\n",
    "\n",
    "    if i in categorical_small:\n",
    "        categorical_small.remove(i)\n",
    "\n",
    "    elif i in numerical_small:\n",
    "        numerical_small.remove(i)\n",
    "\n",
    "    train_small_dict = df_small_train[categorical_small + numerical_small].to_dict(orient = \"records\")\n",
    "    X_small_train = dv.fit_transform(train_small_dict)\n",
    "\n",
    "    val_small_dict = df_small_val[categorical_small + numerical_small].to_dict(orient = \"records\")\n",
    "    X_small_val = dv.transform(val_small_dict)\n",
    "\n",
    "    model.fit(X_small_train, y_train)\n",
    "\n",
    "    y_pred = model.predict_proba(X_small_val)[:, 1]\n",
    "    churn_decision = (y_pred >= 0.5)\n",
    "    print((y_val == churn_decision).mean() - accuracy)\n",
    "\n",
    "    # reset for next iteration\n",
    "    df_small_train = df_train.copy()\n",
    "    df_small_val = df_val.copy()\n",
    "    categorical_small = categorical.copy()\n",
    "    numerical_small = numerical.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "* For this question, we'll see how to use a linear regression model from Scikit-Learn.\n",
    "* We'll need to use the original column `price`. Apply the logarithmic transformation to this column.\n",
    "* Fit the Ridge regression model on the training data with a solver `'sag'`. Set the seed to `42`.\n",
    "* This model also has a parameter `alpha`. Let's try the following values: `[0, 0.01, 0.1, 1, 10]`.\n",
    "* Round your RMSE scores to 3 decimal digits.\n",
    "\n",
    "Which of these alphas leads to the best RMSE on the validation set?\n",
    "\n",
    "- 0\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df.drop([\"Engine Fuel Type\", \"Driven_Wheels\", \"Number of Doors\", \"Market Category\", \"Vehicle Size\", \"Popularity\"], axis = 1, inplace = True)\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "df = df.fillna(0)\n",
    "df.rename(columns={\"msrp\": \"price\"}, inplace = True)\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.price.values\n",
    "y_val = df_val.price.values\n",
    "\n",
    "del df_train[\"price\"]\n",
    "del df_val[\"price\"]\n",
    "\n",
    "numerical = [\"year\", \"engine_hp\", \"engine_cylinders\", \"highway_mpg\", \"city_mpg\"]\n",
    "categorical = [\"make\", \"model\", \"transmission_type\", \"vehicle_style\"]\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient = \"records\")\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient = \"records\")\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "32034.67\n",
      "0.01\n",
      "31320.825\n",
      "0.1\n",
      "31292.046\n",
      "1\n",
      "31803.416\n",
      "10\n",
      "41567.732\n"
     ]
    }
   ],
   "source": [
    "alphas = [0, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for i in alphas:\n",
    "    ridge = Ridge(alpha = i, solver = \"sag\", random_state = 42)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_val)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "    print(i)\n",
    "    print(round(rmse, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are wild RMSE values, no idea why I got them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
